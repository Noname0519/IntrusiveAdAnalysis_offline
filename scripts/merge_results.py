import os
import pandas as pd
import json
import shutil
from datetime import datetime
import glob

class AppAnalyzer:
    def __init__(self, master_csv_path="master_apps.csv", master_txt_path="checked_apks.txt"):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            master_csv_path: ä¸»CSVæ–‡ä»¶è·¯å¾„ï¼ŒåŒ…å«æ‰€æœ‰åº”ç”¨ä¿¡æ¯
            master_txt_path: ä¸»TXTæ–‡ä»¶è·¯å¾„ï¼ŒåŒ…å«å·²æ£€æµ‹çš„åº”ç”¨åç§°åˆ—è¡¨
        """
        self.master_csv_path = master_csv_path
        self.master_txt_path = master_txt_path
        
        # åˆå§‹åŒ–ä¸»CSVçš„åˆ—
        self.csv_columns = [
            'app_name', 'app_path', 'package_name', 'apk_path', 'sha256', 
            'is_tested', 'test_date', 'utg_exists', 'app_output_dir',
            'year', 'size', 'contain_ad', 'sensor_test_done', 'timestamp'
        ]
        
        # ç¡®ä¿ä¸»æ–‡ä»¶å­˜åœ¨
        self._ensure_master_files()
    
    def _ensure_master_files(self):
        """ç¡®ä¿ä¸»CSVå’ŒTXTæ–‡ä»¶å­˜åœ¨"""
        # ç¡®ä¿CSVæ–‡ä»¶å­˜åœ¨ä¸”æœ‰æ­£ç¡®çš„åˆ—
        if not os.path.exists(self.master_csv_path):
            df = pd.DataFrame(columns=self.csv_columns)
            df.to_csv(self.master_csv_path, index=False)
            print(f"[+] åˆ›å»ºæ–°çš„ä¸»CSVæ–‡ä»¶: {self.master_csv_path}")
        
        # ç¡®ä¿TXTæ–‡ä»¶å­˜åœ¨
        if not os.path.exists(self.master_txt_path):
            with open(self.master_txt_path, 'w', encoding='utf-8') as f:
                f.write("# å·²æ£€æµ‹åº”ç”¨åˆ—è¡¨\n")
            print(f"[+] åˆ›å»ºæ–°çš„ä¸»TXTæ–‡ä»¶: {self.master_txt_path}")
    
    def generate_master_files_from_analyze(self, analyzed_apps):
        """
        ä»åˆ†æç»“æœç”Ÿæˆä¸»CSVå’ŒTXTæ–‡ä»¶
        
        Args:
            analyzed_apps: åˆ†æè¿‡çš„åº”ç”¨åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯åŒ…å«åº”ç”¨ä¿¡æ¯çš„å­—å…¸
        """
        try:
            # è¯»å–ç°æœ‰çš„ä¸»CSV
            if os.path.exists(self.master_csv_path) and os.path.getsize(self.master_csv_path) > 0:
                master_df = pd.read_csv(self.master_csv_path, dtype=str).fillna("")
            else:
                master_df = pd.DataFrame(columns=self.csv_columns)
            
            # è¯»å–ç°æœ‰çš„TXTæ–‡ä»¶
            existing_apps = set()
            if os.path.exists(self.master_txt_path) and os.path.getsize(self.master_txt_path) > 0:
                with open(self.master_txt_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith('#'):
                            existing_apps.add(line)
            
            added_count = 0
            updated_count = 0
            
            # å¤„ç†æ¯ä¸ªåˆ†æè¿‡çš„åº”ç”¨
            for app_info in analyzed_apps:
                app_name = app_info.get('app_name', '')
                if not app_name:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                existing_mask = master_df['app_name'] == app_name
                
                if existing_mask.any():
                    # æ›´æ–°ç°æœ‰è®°å½•
                    for idx in master_df[existing_mask].index:
                        for col, value in app_info.items():
                            if col in master_df.columns and value:
                                master_df.loc[idx, col] = value
                        master_df.loc[idx, 'is_tested'] = 'TRUE'
                        master_df.loc[idx, 'test_date'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    updated_count += 1
                else:
                    # æ·»åŠ æ–°è®°å½•
                    new_row = {col: '' for col in self.csv_columns}
                    new_row.update(app_info)
                    new_row['is_tested'] = 'TRUE'
                    new_row['test_date'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    
                    master_df = pd.concat([master_df, pd.DataFrame([new_row])], ignore_index=True)
                    added_count += 1
                
                # æ·»åŠ åˆ°TXTæ–‡ä»¶ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                if app_name not in existing_apps:
                    existing_apps.add(app_name)
            
            # ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
            master_df.to_csv(self.master_csv_path, index=False)
            
            with open(self.master_txt_path, 'w', encoding='utf-8') as f:
                f.write("# å·²æ£€æµ‹åº”ç”¨åˆ—è¡¨\n")
                for app_name in sorted(existing_apps):
                    f.write(f"{app_name}\n")
            
            print(f"\n[+] ä¸»æ–‡ä»¶æ›´æ–°å®Œæˆ:")
            print(f"    - æ–°å¢åº”ç”¨: {added_count}")
            print(f"    - æ›´æ–°åº”ç”¨: {updated_count}")
            print(f"    - æ€»åº”ç”¨æ•°: {len(master_df)}")
            print(f"    - CSVæ–‡ä»¶: {self.master_csv_path}")
            print(f"    - TXTæ–‡ä»¶: {self.master_txt_path}")
            
            return True
            
        except Exception as e:
            print(f"[!] ç”Ÿæˆä¸»æ–‡ä»¶å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def scan_multiple_folders(self, folder_paths, recursive=True):
        """
        æ‰«æå¤šä¸ªæ–‡ä»¶å¤¹ï¼ŒæŸ¥æ‰¾æ–°çš„åº”ç”¨æµ‹è¯•ç»“æœ
        
        Args:
            folder_paths: æ–‡ä»¶å¤¹è·¯å¾„åˆ—è¡¨
            recursive: æ˜¯å¦é€’å½’æœç´¢å­æ–‡ä»¶å¤¹
            
        Returns:
            list: æ–°å‘ç°çš„åº”ç”¨ä¿¡æ¯åˆ—è¡¨
        """
        try:
            # è¯»å–å·²æ£€æŸ¥çš„åº”ç”¨åˆ—è¡¨
            checked_apps = self._load_checked_apps()
            
            new_apps = []
            
            for folder_path in folder_paths:
                if not os.path.exists(folder_path):
                    print(f"[!] æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_path}")
                    continue
                
                print(f"[+] æ‰«ææ–‡ä»¶å¤¹: {folder_path}")
                
                # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„åº”ç”¨ç»“æœæ–‡ä»¶å¤¹
                app_folders = self._find_app_folders(folder_path, recursive)
                print(f"    æ‰¾åˆ° {len(app_folders)} ä¸ªå¯èƒ½çš„åº”ç”¨æ–‡ä»¶å¤¹")
                
                for app_folder in app_folders:
                    app_name = os.path.basename(app_folder.rstrip(os.sep))
                    
                    # æ£€æŸ¥æ˜¯å¦å·²è®°å½•
                    if app_name in checked_apps:
                        continue
                    
                    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨utg.js
                    utg_path = os.path.join(app_folder, "utg.js")
                    if not os.path.exists(utg_path):
                        continue
                    
                    # æå–åº”ç”¨ä¿¡æ¯
                    app_info = self._extract_app_info(app_folder, app_name)
                    if app_info:
                        new_apps.append(app_info)
                        print(f"[+] å‘ç°æ–°åº”ç”¨: {app_name}")
            
            return new_apps
            
        except Exception as e:
            print(f"[!] æ‰«ææ–‡ä»¶å¤¹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def _load_checked_apps(self):
        """åŠ è½½å·²æ£€æŸ¥çš„åº”ç”¨åˆ—è¡¨"""
        checked_apps = set()
        
        if os.path.exists(self.master_txt_path) and os.path.getsize(self.master_txt_path) > 0:
            with open(self.master_txt_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        checked_apps.add(line)
        
        return checked_apps
    
    def _find_app_folders(self, root_path, recursive=True):
        """æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„åº”ç”¨æ–‡ä»¶å¤¹"""
        app_folders = []
        
        if recursive:
            # é€’å½’æœç´¢æ‰€æœ‰å­æ–‡ä»¶å¤¹
            for root, dirs, files in os.walk(root_path):
                # æ£€æŸ¥å½“å‰ç›®å½•æ˜¯å¦åŒ…å«utg.js
                if "utg.js" in files:
                    app_folders.append(root)
        else:
            # åªæœç´¢ç›´æ¥å­æ–‡ä»¶å¤¹
            for item in os.listdir(root_path):
                item_path = os.path.join(root_path, item)
                if os.path.isdir(item_path):
                    utg_path = os.path.join(item_path, "utg.js")
                    if os.path.exists(utg_path):
                        app_folders.append(item_path)
        
        return app_folders
    
    def _extract_app_info(self, app_folder, app_name):
        """ä»åº”ç”¨æ–‡ä»¶å¤¹ä¸­æå–ä¿¡æ¯"""
        try:
            app_info = {
                'app_name': app_name,
                'app_path': app_folder,
                'utg_exists': 'TRUE',
                'test_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
            # å°è¯•ä»utg.jsä¸­æå–æ›´å¤šä¿¡æ¯
            utg_path = os.path.join(app_folder, "utg.js")
            if os.path.exists(utg_path):
                try:
                    with open(utg_path, 'r', encoding='utf-8') as f:
                        utg_content = f.read()
                        # å°è¯•è§£æJSONï¼ˆutg.jsé€šå¸¸æ˜¯JSONæ ¼å¼ï¼‰
                        if utg_content.strip().startswith('{'):
                            utg_data = json.loads(utg_content)
                            package_name = utg_data.get('packageName', '')
                            if package_name:
                                app_info['package_name'] = package_name
                except:
                    # å¦‚æœè§£æå¤±è´¥ï¼Œè·³è¿‡
                    pass
            
            # å°è¯•æŸ¥æ‰¾APKæ–‡ä»¶
            apk_files = glob.glob(os.path.join(app_folder, "*.apk"))
            if apk_files:
                app_info['apk_path'] = apk_files[0]
            
            # å°è¯•è¯»å–å…¶ä»–å¯èƒ½å­˜åœ¨çš„å…ƒæ•°æ®æ–‡ä»¶
            meta_files = ['app_info.json', 'metadata.json', 'analysis_result.json']
            for meta_file in meta_files:
                meta_path = os.path.join(app_folder, meta_file)
                if os.path.exists(meta_path):
                    try:
                        with open(meta_path, 'r', encoding='utf-8') as f:
                            meta_data = json.load(f)
                            # æå–æœ‰ç”¨çš„å­—æ®µ
                            for key in ['sha256', 'year', 'size', 'contain_ad', 'sensor_test_done', 'timestamp']:
                                if key in meta_data:
                                    app_info[key] = str(meta_data[key])
                    except:
                        pass
            
            return app_info
            
        except Exception as e:
            print(f"[!] æå–åº”ç”¨ä¿¡æ¯å¤±è´¥ {app_folder}: {e}")
            return None
    
    def add_new_apps_to_master(self, folder_paths, recursive=True, auto_save=True):
        """
        æ‰«ææ–‡ä»¶å¤¹å¹¶å°†æ–°å‘ç°çš„åº”ç”¨æ·»åŠ åˆ°ä¸»æ–‡ä»¶
        
        Args:
            folder_paths: æ–‡ä»¶å¤¹è·¯å¾„åˆ—è¡¨
            recursive: æ˜¯å¦é€’å½’æœç´¢
            auto_save: æ˜¯å¦è‡ªåŠ¨ä¿å­˜åˆ°ä¸»æ–‡ä»¶
            
        Returns:
            tuple: (æ–°åº”ç”¨åˆ—è¡¨, æ˜¯å¦æˆåŠŸ)
        """
        try:
            new_apps = self.scan_multiple_folders(folder_paths, recursive)
            
            if not new_apps:
                print("[!] æœªå‘ç°æ–°çš„åº”ç”¨")
                return [], True
            
            print(f"\n[+] å‘ç° {len(new_apps)} ä¸ªæ–°åº”ç”¨:")
            for app in new_apps:
                print(f"    - {app['app_name']} ({app.get('package_name', 'Unknown')})")
            
            if auto_save:
                success = self._add_apps_to_master_files(new_apps)
                return new_apps, success
            else:
                return new_apps, True
            
        except Exception as e:
            print(f"[!] æ·»åŠ æ–°åº”ç”¨å¤±è´¥: {e}")
            return [], False
    
    def _add_apps_to_master_files(self, new_apps):
        """å°†æ–°åº”ç”¨æ·»åŠ åˆ°ä¸»æ–‡ä»¶"""
        try:
            # è¯»å–ç°æœ‰CSV
            if os.path.exists(self.master_csv_path) and os.path.getsize(self.master_csv_path) > 0:
                master_df = pd.read_csv(self.master_csv_path, dtype=str).fillna("")
            else:
                master_df = pd.DataFrame(columns=self.csv_columns)
            
            # è¯»å–ç°æœ‰TXT
            checked_apps = self._load_checked_apps()
            
            added_count = 0
            
            # æ·»åŠ æ–°åº”ç”¨åˆ°CSV
            for app_info in new_apps:
                app_name = app_info.get('app_name', '')
                if not app_name or app_name in checked_apps:
                    continue
                
                # åˆ›å»ºæ–°è¡Œ
                new_row = {col: '' for col in self.csv_columns}
                new_row.update(app_info)
                new_row['is_tested'] = 'TRUE'
                
                master_df = pd.concat([master_df, pd.DataFrame([new_row])], ignore_index=True)
                checked_apps.add(app_name)
                added_count += 1
            
            # ä¿å­˜æ–‡ä»¶
            master_df.to_csv(self.master_csv_path, index=False)
            
            with open(self.master_txt_path, 'w', encoding='utf-8') as f:
                f.write("# å·²æ£€æµ‹åº”ç”¨åˆ—è¡¨\n")
                for app_name in sorted(checked_apps):
                    f.write(f"{app_name}\n")
            
            print(f"[+] æˆåŠŸæ·»åŠ  {added_count} ä¸ªæ–°åº”ç”¨åˆ°ä¸»æ–‡ä»¶")
            return True
            
        except Exception as e:
            print(f"[!] æ·»åŠ åˆ°ä¸»æ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def get_master_stats(self):
        """è·å–ä¸»æ–‡ä»¶çš„ç»Ÿè®¡ä¿¡æ¯"""
        try:
            if not os.path.exists(self.master_csv_path) or os.path.getsize(self.master_csv_path) == 0:
                return {"total_apps": 0, "tested_apps": 0}
            
            df = pd.read_csv(self.master_csv_path, dtype=str).fillna("")
            
            total_apps = len(df)
            tested_apps = len(df[df['is_tested'].str.upper().isin(['TRUE', 'T', '1', 'YES', 'Y'])])
            utg_exists = len(df[df['utg_exists'].str.upper().isin(['TRUE', 'T', '1', 'YES', 'Y'])])
            
            stats = {
                "total_apps": total_apps,
                "tested_apps": tested_apps,
                "utg_exists": utg_exists,
                "tested_percentage": (tested_apps / total_apps * 100) if total_apps > 0 else 0
            }
            
            return stats
            
        except Exception as e:
            print(f"[!] è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {"total_apps": 0, "tested_apps": 0}
    
    def print_master_stats(self):
        """æ‰“å°ä¸»æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.get_master_stats()
        
        print(f"\nğŸ“Š ä¸»æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æ€»åº”ç”¨æ•°: {stats['total_apps']}")
        print(f"   å·²æµ‹è¯•åº”ç”¨: {stats['tested_apps']}")
        print(f"   æœ‰UTGæ–‡ä»¶: {stats['utg_exists']}")
        print(f"   æµ‹è¯•å®Œæˆç‡: {stats['tested_percentage']:.1f}%")

# ä½¿ç”¨ç¤ºä¾‹
def main():
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = AppAnalyzer(
        master_csv_path="all_apps_master.csv",
        master_txt_path="checked_apps.txt"
    )
    
    # ç¤ºä¾‹1: ä»åˆ†æç»“æœç”Ÿæˆä¸»æ–‡ä»¶
    # analyzed_apps = ["F:\\test\\merge_output.csv",
    #                  "E:\\test\\untested_simulator1.csv",

    #                  ]  # ä½ çš„åˆ†æç»“æœ
    # analyzer.generate_master_files_from_analyze(analyzed_apps)
    
    # ç¤ºä¾‹2: æ‰«æå¤šä¸ªæ–‡ä»¶å¤¹å¹¶æ·»åŠ æ–°åº”ç”¨
    folders_to_scan = [
        "D:\\NKU\\Work\\Work2\\fraudulent_output",
        "D:\\NKU\\Work\\Work2\\datasets\\manual_analysis\\output", 
        "D:\\NKU\\Work\\Work2\\datasets\\chin\\output",
        "D:\\NKU\\Work\\Work2\\datasets\\manual_analysis\\test_adgpe_test"
    ]
    
    new_apps, success = analyzer.add_new_apps_to_master(folders_to_scan, recursive=True)
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    analyzer.print_master_stats()

if __name__ == "__main__":
    main()